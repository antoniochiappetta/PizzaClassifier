{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Unsupported colorspace format. Currently, only RGB and Grayscale are supported.\t file: ../../data/train/ortolana/pizza-ortolana-a1742-16.jpg</pre>"
      ],
      "text/plain": [
       "Unsupported colorspace format. Currently, only RGB and Grayscale are supported.\t file: ../../data/train/ortolana/pizza-ortolana-a1742-16.jpg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_dir = \"../../data/\"\n",
    "train_data = tc.image_analysis.load_images(images_dir + \"train\", with_path=True)\n",
    "val_data = tc.image_analysis.load_images(images_dir + \"val\", with_path=True)\n",
    "test_data = tc.image_analysis.load_images(images_dir + \"test\", with_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_data[\"label\"] = train_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))\n",
    "val_data[\"label\"] = val_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))\n",
    "test_data[\"label\"] = test_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Available models:\n",
    "- squeezenet_v1.1\n",
    "- resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tc.image_classifier.create(train_data,\n",
    "#                                    validation_set=val_data,\n",
    "#                                    target=\"label\",\n",
    "#                                    model=\"squeezenet_v1.1\",\n",
    "#                                    verbose=True,\n",
    "#                                    max_iterations=100,\n",
    "#                                    l2_penalty=10.0,\n",
    "#                                    l1_penalty=0.0,\n",
    "#                                    convergence_threshold=1e-8\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature extraction on resized images...\n",
      "Completed  64/958\n"
     ]
    }
   ],
   "source": [
    "# Extract and save features\n",
    "\n",
    "from turicreate.toolkits import _pre_trained_models\n",
    "from turicreate.toolkits import _image_feature_extractor\n",
    "\n",
    "ptModel = _pre_trained_models.MODELS[\"squeezenet_v1.1\"]()\n",
    "feature_extractor = _image_feature_extractor.MXFeatureExtractor(ptModel)\n",
    "\n",
    "train_features = feature_extractor.extract_features(train_data, \"image\", verbose=True)\n",
    "extracted_train_features = tc.SFrame({\"label\": train_data[\"label\"], \"__image_features__\": train_features})\n",
    "extracted_train_features.save(\"train_features_tc.sframe\")\n",
    "\n",
    "val_features = feature_extractor.extract_features(val_data, \"image\", verbose=True)\n",
    "extracted_val_features = tc.SFrame({\"label\": val_data[\"label\"], \"__image_features__\": val_features})\n",
    "extracted_val_features.save(\"val_features_tc.sframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = tc.logistic_classifier.create(extracted_train_features,\n",
    "                                         features=[\"__image_features__\"],\n",
    "                                         target=\"label\",\n",
    "                                         validation_set=extracted_val_features,\n",
    "                                         max_iterations=200,\n",
    "                                         seed=None,\n",
    "                                         verbose=True,\n",
    "                                         l2_penalty=10.0,\n",
    "                                         l1_penalty=0.0,\n",
    "                                         convergence_threshold=1e-8\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turicreate.toolkits.image_classifier import ImageClassifier\n",
    "\n",
    "state = {\n",
    "    'classifier': lr_model,\n",
    "    'model': ptModel.name,\n",
    "    'max_iterations': lr_model.max_iterations,\n",
    "    'feature_extractor': feature_extractor,\n",
    "    'input_image_shape': ptModel.input_image_shape,\n",
    "    'target': lr_model.target,\n",
    "    'feature': 'image',\n",
    "    'num_features': 1,\n",
    "    'num_classes': lr_model.num_classes,\n",
    "    'classes': lr_model.classes,\n",
    "    'num_examples': lr_model.num_examples,\n",
    "    'training_time': lr_model.training_time,\n",
    "    'training_loss': lr_model.training_loss\n",
    "}\n",
    "\n",
    "model = ImageClassifier(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.classify(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data, output_type=\"probability_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_with_pred = test_data.add_columns(output)\n",
    "imgs_filtered = imgs_with_pred[(imgs_with_pred[\"probability\"] > 0.9) & (imgs_with_pred[\"label\"] != imgs_with_pred[\"class\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_confusion_matrix(metrics, labels):\n",
    "    num_labels = len(labels)\n",
    "    label_to_index = {l:i for i,l in enumerate(labels)}\n",
    "    \n",
    "    conf = np.zeros((num_labels, num_labels), dtype=np.int)\n",
    "    for row in metrics[\"confusion_matrix\"]:\n",
    "        true_label = label_to_index[row[\"target_label\"]]\n",
    "        pred_label = label_to_index[row[\"predicted_label\"]]\n",
    "        conf[true_label, pred_label] = row[\"count\"]\n",
    "        \n",
    "    return conf\n",
    "\n",
    "def plot_confusion_matrix(conf, labels, figsize=(8, 8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    heatmap = sns.heatmap(conf, annot=True, fmt=\"d\")\n",
    "    heatmap.xaxis.set_ticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "    heatmap.yaxis.set_ticklabels(labels, rotation=0, ha=\"right\", fontsize=12)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=12)\n",
    "    plt.ylabel(\"True label\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_data[\"label\"].unique().sort()\n",
    "conf = compute_confusion_matrix(metrics, labels)\n",
    "plot_confusion_matrix(conf, labels, figsize=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(labels):\n",
    "    correct = conf[i, i]\n",
    "    images_per_class = conf[i].sum()\n",
    "    print(\"%10s %.1f%%\" % (label, 100. * correct/images_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2index = {v:k for k,v in enumerate(test_data[\"label\"].unique().sort())}\n",
    "predicted_labels = np.argmax(predictions, axis=-1)\n",
    "target_labels = list(map(lambda l: class2index[l], test_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find for which images the predicted class is wrong\n",
    "wrong_images = np.where(predicted_labels != target_labels)[0]\n",
    "\n",
    "# For every prediction, find the largest probability value;\n",
    "# this is the probability of the winning class for this image\n",
    "probs_max = np.max(np.array(predictions), axis=-1)\n",
    "\n",
    "# Sort the probabilities from the wrong images from low to high\n",
    "idx = np.argsort(probs_max[wrong_images])\n",
    "\n",
    "# Reverse the order (high to low), and keep the 5 highest ones\n",
    "idx = idx[::-1][:5]\n",
    "\n",
    "# Get the indices of the images with the worst predictions\n",
    "worst_predictions = wrong_images[idx]\n",
    "\n",
    "index2class = {k:v for k,v in enumerate(test_data[\"label\"].unique().sort())}\n",
    "\n",
    "for i in worst_predictions:\n",
    "    print(\"%s was predicted as '%s' %.4f\" % (test_data[\"path\"][i],\n",
    "                                             index2class[predicted_labels[i]],\n",
    "                                             probs_max[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Pizza_tc.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_coreml(\"Pizza_tc.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
