{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../../data/\"\n",
    "train_data = tc.image_analysis.load_images(images_dir + \"train\", with_path=True)\n",
    "val_data = tc.image_analysis.load_images(images_dir + \"val\", with_path=True)\n",
    "test_data = tc.image_analysis.load_images(images_dir + \"test\", with_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_data[\"label\"] = train_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))\n",
    "val_data[\"label\"] = val_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))\n",
    "test_data[\"label\"] = test_data[\"path\"].apply(lambda path: os.path.basename(os.path.split(path)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Available models:\n",
    "- squeezenet_v1.1\n",
    "- resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tc.image_classifier.create(train_data,\n",
    "#                                    validation_set=val_data,\n",
    "#                                    target=\"label\",\n",
    "#                                    model=\"squeezenet_v1.1\",\n",
    "#                                    verbose=True,\n",
    "#                                    max_iterations=100,\n",
    "#                                    l2_penalty=10.0,\n",
    "#                                    l1_penalty=0.0,\n",
    "#                                    convergence_threshold=1e-8\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature extraction on resized images...\n",
      "Completed  64/719\n",
      "Completed 128/719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-57172f8b0a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_image_feature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mextracted_train_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__image_features__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mextracted_train_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_features_tc.sframe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/turienv/lib/python3.7/site-packages/turicreate/toolkits/_image_feature_extractor.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, dataset, feature, batch_size, verbose)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mdataIter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_next\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mrequest_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Produce request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0mconsume_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0mconsume_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/turienv/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/turienv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract and save features\n",
    "\n",
    "from turicreate.toolkits import _pre_trained_models\n",
    "from turicreate.toolkits import _image_feature_extractor\n",
    "\n",
    "ptModel = _pre_trained_models.MODELS[\"squeezenet_v1.1\"]()\n",
    "feature_extractor = _image_feature_extractor.MXFeatureExtractor(ptModel)\n",
    "\n",
    "train_features = feature_extractor.extract_features(train_data, \"image\", verbose=True)\n",
    "extracted_train_features = tc.SFrame({\"label\": train_data[\"label\"], \"__image_features__\": train_features})\n",
    "extracted_train_features.save(\"train_features_tc.sframe\")\n",
    "\n",
    "val_features = feature_extractor.extract_features(val_data, \"image\", verbose=True)\n",
    "extracted_val_features = tc.SFrame({\"label\": val_data[\"label\"], \"__image_features__\": val_features})\n",
    "extracted_val_features.save(\"val_features_tc.sframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = tc.logistic_classifier.create(extracted_train_features,\n",
    "                                         features=[\"__image_features__\"],\n",
    "                                         target=\"label\",\n",
    "                                         validation_set=extracted_val_features,\n",
    "                                         max_iterations=200,\n",
    "                                         seed=None,\n",
    "                                         verbose=True,\n",
    "                                         l2_penalty=10.0,\n",
    "                                         l1_penalty=0.0,\n",
    "                                         convergence_threshold=1e-8\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turicreate.toolkits.image_classifier import ImageClassifier\n",
    "\n",
    "state = {\n",
    "    'classifier': lr_model,\n",
    "    'model': ptModel.name,\n",
    "    'max_iterations': lr_model.max_iterations,\n",
    "    'feature_extractor': feature_extractor,\n",
    "    'input_image_shape': ptModel.input_image_shape,\n",
    "    'target': lr_model.target,\n",
    "    'feature': 'image',\n",
    "    'num_features': 1,\n",
    "    'num_classes': lr_model.num_classes,\n",
    "    'classes': lr_model.classes,\n",
    "    'num_examples': lr_model.num_examples,\n",
    "    'training_time': lr_model.training_time,\n",
    "    'training_loss': lr_model.training_loss\n",
    "}\n",
    "\n",
    "model = ImageClassifier(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.classify(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data, output_type=\"probability_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_with_pred = test_data.add_columns(output)\n",
    "imgs_filtered = imgs_with_pred[(imgs_with_pred[\"probability\"] > 0.9) & (imgs_with_pred[\"label\"] != imgs_with_pred[\"class\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_confusion_matrix(metrics, labels):\n",
    "    num_labels = len(labels)\n",
    "    label_to_index = {l:i for i,l in enumerate(labels)}\n",
    "    \n",
    "    conf = np.zeros((num_labels, num_labels), dtype=np.int)\n",
    "    for row in metrics[\"confusion_matrix\"]:\n",
    "        true_label = label_to_index[row[\"target_label\"]]\n",
    "        pred_label = label_to_index[row[\"predicted_label\"]]\n",
    "        conf[true_label, pred_label] = row[\"count\"]\n",
    "        \n",
    "    return conf\n",
    "\n",
    "def plot_confusion_matrix(conf, labels, figsize=(8, 8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    heatmap = sns.heatmap(conf, annot=True, fmt=\"d\")\n",
    "    heatmap.xaxis.set_ticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "    heatmap.yaxis.set_ticklabels(labels, rotation=0, ha=\"right\", fontsize=12)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=12)\n",
    "    plt.ylabel(\"True label\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_data[\"label\"].unique().sort()\n",
    "conf = compute_confusion_matrix(metrics, labels)\n",
    "plot_confusion_matrix(conf, labels, figsize=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(labels):\n",
    "    correct = conf[i, i]\n",
    "    images_per_class = conf[i].sum()\n",
    "    print(\"%10s %.1f%%\" % (label, 100. * correct/images_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2index = {v:k for k,v in enumerate(test_data[\"label\"].unique().sort())}\n",
    "predicted_labels = np.argmax(predictions, axis=-1)\n",
    "target_labels = list(map(lambda l: class2index[l], test_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find for which images the predicted class is wrong\n",
    "wrong_images = np.where(predicted_labels != target_labels)[0]\n",
    "\n",
    "# For every prediction, find the largest probability value;\n",
    "# this is the probability of the winning class for this image\n",
    "probs_max = np.max(np.array(predictions), axis=-1)\n",
    "\n",
    "# Sort the probabilities from the wrong images from low to high\n",
    "idx = np.argsort(probs_max[wrong_images])\n",
    "\n",
    "# Reverse the order (high to low), and keep the 5 highest ones\n",
    "idx = idx[::-1][:5]\n",
    "\n",
    "# Get the indices of the images with the worst predictions\n",
    "worst_predictions = wrong_images[idx]\n",
    "\n",
    "index2class = {k:v for k,v in enumerate(test_data[\"label\"].unique().sort())}\n",
    "\n",
    "for i in worst_predictions:\n",
    "    print(\"%s was predicted as '%s' %.4f\" % (test_data[\"path\"][i],\n",
    "                                             index2class[predicted_labels[i]],\n",
    "                                             probs_max[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Pizza_tc.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_coreml(\"Pizza_tc.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
