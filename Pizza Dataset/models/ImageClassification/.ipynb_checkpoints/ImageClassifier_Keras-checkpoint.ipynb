{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import optimizers, callbacks\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "from keras.applications.mobilenet import preprocess_input # correct preprocessing for this model\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   preprocessing_function=preprocess_input)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "images_dir = \"../../data/\"\n",
    "train_data_dir = images_dir + \"train/\"\n",
    "val_data_dir = images_dir + \"val/\"\n",
    "test_data_dir = images_dir + \"test/\"\n",
    "batch_size = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                   target_size=(image_width, image_height),\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_data_dir,\n",
    "                                               target_size=(image_width, image_height),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                 target_size=(image_width, image_height),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet base model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "base_model = MobileNet(input_shape=(image_height, image_width, 3),\n",
    "                      include_top=False, # Leave off classifier layers, use it only as feature extractor\n",
    "                      weights=\"imagenet\",\n",
    "                      pooling=None) # Leave off classifier layers, use it only as feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "from keras import regularizers\n",
    "top_model = Sequential()\n",
    "top_model.add(base_model)\n",
    "top_model.add(GlobalAveragePooling2D())\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(num_classes, kernel_regularizer=regularizers.l2(0.001)))\n",
    "top_model.add(Activation(\"softmax\"))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "top_model.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer=optimizers.Adam(lr=1e-3),\n",
    "                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints_keras/\"\n",
    "checkpoint_name = (checkpoint_dir + \"imageclassifier-{val_loss:.4f}-{val_acc:.4f}.hdf5\")\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "def create_callbacks():\n",
    "    return [\n",
    "        callbacks.EarlyStopping(monitor=\"val_acc\",\n",
    "                               patience=10,\n",
    "                               verbose=1),\n",
    "        callbacks.ModelCheckpoint(checkpoint_name,\n",
    "                                 monitor=\"val_acc\",\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True)\n",
    "    ]\n",
    "\n",
    "my_callbacks = create_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/envs/kerasenv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = top_model.fit_generator(train_generator,\n",
    "                                 steps_per_epoch=len(train_generator),\n",
    "                                 epochs=10,\n",
    "                                 callbacks=my_callbacks,\n",
    "                                 validation_data=val_generator,\n",
    "                                 validation_steps=len(val_generator),\n",
    "                                 workers=8)\n",
    "histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_histories():\n",
    "    history = {\n",
    "        \"loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "    \n",
    "    for h in histories:\n",
    "        for k in history.keys():\n",
    "            history[k] = h.history[k]\n",
    "    return history\n",
    "\n",
    "history = combine_histories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.plot(history[\"acc\"])\n",
    "    plt.plot(history[\"val_acc\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend([\"Train\", \"Validation\"])\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model(checkpoint_dir + \"imageclassifier-0.1050-0.9875.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate_generator(test_generator,\n",
    "                              steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "probabilities = best_model.predict_generator(test_generator,\n",
    "                                            steps=len(test_generator))\n",
    "predicted_labels = np.argmax(probabilities, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = test_generator.classes\n",
    "\n",
    "from sklearn import metrics\n",
    "conf = metrics.confusion_matrix(target_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(conf, labels, figsize=(8, 8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    heatmap = sns.heatmap(conf, annot=True, fmt=\"d\")\n",
    "    heatmap.xaxis.set_ticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "    heatmap.yaxis.set_ticklabels(labels, rotation=0, ha=\"right\", fontsize=12)\n",
    "    plt.xlabel(\"Predicted label\", fontsize=12)\n",
    "    plt.ylabel(\"True label\", fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "# Find the class names that correspond to the indices\n",
    "labels = [\"\"] * num_classes\n",
    "for k, v in test_generator.class_indices.items():\n",
    "    labels[v] = k\n",
    "    \n",
    "plot_confusion_matrix(conf, labels, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find for which images the predicted class is wrong\n",
    "wrong_images = np.where(predicted_labels != target_labels)[0]\n",
    "\n",
    "# For every prediction, find the largest probability value;\n",
    "# this is the probability of the winning class for this image\n",
    "probs_max = np.max(probabilities, axis=-1)\n",
    "\n",
    "# Sort the probabilities from the wrong images from low to high\n",
    "idx = np.argsort(probs_max[wrong_images])\n",
    "\n",
    "# Reverse the order (high to low), and keep the 5 highest ones\n",
    "idx = idx[::-1][:5]\n",
    "\n",
    "# Get the indices of the images with the worst predictions\n",
    "worst_predictions = wrong_images[idx]\n",
    "\n",
    "index2class = {v:k for k,v in test_generator.class_indices.items()}\n",
    "\n",
    "for i in worst_predictions:\n",
    "    print(\"%s was predicted as '%s' %.4f\" % (test_generator.filenames[i],\n",
    "                                             index2class[predicted_labels[i]],\n",
    "                                             probs_max[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "labels = [\"diavola\", \"margherita\", \"marinara\", \"multiple\", \"other\"]\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert(best_model,\n",
    "                                                   input_names=\"image\",\n",
    "                                                   image_input_names=\"image\",\n",
    "                                                   output_names=\"labelProbability\",\n",
    "                                                   predicted_feature_name=\"label\",\n",
    "                                                   red_bias=-1, # normalization to interval [-1,+1]\n",
    "                                                   green_bias=-1,\n",
    "                                                   blue_bias=-1,\n",
    "                                                   image_scale=2/255.0,\n",
    "                                                   class_labels=labels)\n",
    "\n",
    "coreml_model.author = \"Antonio Chiappetta\"\n",
    "coreml_model.license = \"Public Domain\"\n",
    "coreml_model.short_description = \"A machine learning model that has been trained to distinguish different types of pizza. Currently supported: margherita, marinara.\"\n",
    "coreml_model.input_description[\"image\"] = \"Input image\"\n",
    "coreml_model.output_description[\"labelProbability\"] = \"Prediction probabilities\"\n",
    "coreml_model.output_description[\"label\"] = \"Class label of top prediction\"\n",
    "\n",
    "coreml_model.save(\"Pizza_keras.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
